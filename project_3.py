# -*- coding: utf-8 -*-
"""Project 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19A-CYj1XWoqNo6DVOvDuLtMnuimydN-m
"""

import time
import random
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict
import sys
import gc

# Increase recursion limit for large graphs
sys.setrecursionlimit(50000)

class Graph:
    """Graph representation using adjacency list"""
    def __init__(self, n):
        self.n = n
        self.adj = defaultdict(list)

    def add_edge(self, u, v):
        """Add undirected edge"""
        self.adj[u].append(v)
        self.adj[v].append(u)

    def get_adjacency_list(self):
        """Return adjacency list"""
        return [self.adj[i] for i in range(self.n)]

def find_articulation_points(graph, n):
    """
    Find all articulation points in O(n + m) time using DFS
    Returns: set of articulation points
    """
    discovery = [-1] * n
    low = [-1] * n
    parent = [-1] * n
    articulation_points = set()
    time_counter = [0]

    def dfs(u):
        children = 0
        discovery[u] = low[u] = time_counter[0]
        time_counter[0] += 1

        for v in graph[u]:
            if discovery[v] == -1:  # Unvisited
                children += 1
                parent[v] = u
                dfs(v)

                # Update low value
                low[u] = min(low[u], low[v])

                # Check articulation point conditions
                if parent[u] == -1 and children > 1:
                    articulation_points.add(u)

                if parent[u] != -1 and low[v] >= discovery[u]:
                    articulation_points.add(u)

            elif v != parent[u]:  # Back edge
                low[u] = min(low[u], discovery[v])

    # Run DFS from all unvisited vertices
    for i in range(n):
        if discovery[i] == -1:
            dfs(i)

    return articulation_points

def is_biconnected(graph, n):
    """Check if graph is biconnected (no articulation points)"""
    if n < 2:
        return True
    articulation_points = find_articulation_points(graph, n)
    return len(articulation_points) == 0

def generate_random_connected_graph(n, m):
    """
    Generate a random connected graph with n vertices and m edges
    """
    if m < n - 1:
        m = n - 1
    if m > n * (n - 1) // 2:
        m = n * (n - 1) // 2

    g = Graph(n)
    edges = set()

    # Create spanning tree for connectivity
    vertices = list(range(n))
    random.shuffle(vertices)
    for i in range(1, n):
        u = vertices[i]
        v = vertices[random.randint(0, i-1)]
        edge = tuple(sorted([u, v]))
        edges.add(edge)
        g.add_edge(u, v)

    # Add remaining edges
    while len(edges) < m:
        u = random.randint(0, n-1)
        v = random.randint(0, n-1)
        if u != v:
            edge = tuple(sorted([u, v]))
            if edge not in edges:
                edges.add(edge)
                g.add_edge(u, v)

    return g, len(edges)

def measure_runtime(n, m, num_trials=30):
    """
    Measure average runtime for finding articulation points
    """
    # Generate graph once
    g, actual_m = generate_random_connected_graph(n, m)
    adj_list = g.get_adjacency_list()

    times = []

    # Extended warm-up runs
    for _ in range(10):
        find_articulation_points(adj_list, n)

    # Garbage collection
    gc.collect()
    time.sleep(0.01)  # Brief pause for system stability

    # Measure multiple times
    for _ in range(num_trials):
        start = time.perf_counter()
        find_articulation_points(adj_list, n)
        end = time.perf_counter()

        times.append((end - start) * 1e9)

    # More aggressive outlier removal
    times.sort()
    if len(times) > 12:
        times = times[5:-5]

    # Use mean of middle values for better stability
    return np.mean(times), actual_m

def run_experiments():
    """Run experiments for various graph sizes"""
    test_sizes = [100, 200, 500, 1000, 2000, 3000, 5000, 7000, 10000]

    results = []

    print("Running experiments...")
    print("=" * 80)

    for n in test_sizes:
        m = 2 * n
        print(f"Testing n={n:5d}, target m={m:5d}...", end=" ", flush=True)

        avg_time, actual_m = measure_runtime(n, m, num_trials=30)
        theoretical_ops = n + actual_m

        results.append({
            'n': n,
            'm': actual_m,
            'theoretical_ops': theoretical_ops,
            'experimental_time': avg_time
        })

        print(f"Done. Actual m={actual_m:5d}, Time={avg_time:10.2f} ns")

    return results

def calculate_scaling_constants(results):
    """Calculate scaling constants using linear regression"""
    X = np.array([r['theoretical_ops'] for r in results])
    y = np.array([r['experimental_time'] for r in results])

    A = np.vstack([np.ones(len(X)), X]).T
    coeffs = np.linalg.lstsq(A, y, rcond=None)[0]

    C0, C1 = coeffs
    return C0, C1

def create_output_table(results, C0, C1):
    """Create and display the output table"""
    print("\n" + "=" * 110)
    print("EXPERIMENTAL RESULTS")
    print("=" * 110)
    print(f"\nScaling Model: T(n) = C0 + C1 × (n + m)")
    print(f"  Constant Overhead: C0 = {C0:,.2f} ns")
    print(f"  Per-Operation Cost: C1 = {C1:.4f} ns/operation\n")

    print(f"{'n':<8} {'m':<8} {'Theoretical':<15} {'Scaled Theory':<18} {'Experimental':<18} {'Ratio':<8}")
    print(f"{'':8} {'':8} {'Operations':<15} {'(ns)':<18} {'(ns)':<18} {'Exp/Theory':<8}")
    print("-" * 110)

    for r in results:
        theo_ops = r['theoretical_ops']
        scaled_theory = C0 + C1 * theo_ops
        exp_time = r['experimental_time']
        ratio = exp_time / scaled_theory

        print(f"{r['n']:<8} {r['m']:<8} {theo_ops:<15} {scaled_theory:<18.2f} {exp_time:<18.2f} {ratio:<8.4f}")

    print("=" * 110)

    # Calculate goodness of fit
    predicted = [C0 + C1 * r['theoretical_ops'] for r in results]
    actual = [r['experimental_time'] for r in results]
    residuals = [a - p for a, p in zip(actual, predicted)]
    rss = sum(r**2 for r in residuals)
    tss = sum((a - np.mean(actual))**2 for a in actual)
    r_squared = 1 - (rss / tss)

    print(f"\nGoodness of Fit: R² = {r_squared:.6f}")
    avg_ratio = np.mean([r['experimental_time'] / (C0 + C1 * r['theoretical_ops']) for r in results])
    print(f"Average Exp/Theory Ratio: {avg_ratio:.4f}")

def plot_results(results, C0, C1):
    """Create the comparison plot"""
    n_values = [r['n'] for r in results]
    theoretical_ops = [r['theoretical_ops'] for r in results]
    experimental_times = [r['experimental_time'] for r in results]

    scaled_theoretical = [C0 + C1 * ops for ops in theoretical_ops]

    plt.figure(figsize=(14, 8))

    # Plot experimental data
    plt.plot(n_values, experimental_times, 'bo-', label='Experimental Runtime',
             linewidth=2.5, markersize=10, markeredgewidth=2, markeredgecolor='darkblue')

    # Plot scaled theoretical
    plt.plot(n_values, scaled_theoretical, 'r--', label='Scaled Theoretical Runtime',
             linewidth=2.5, markersize=8, marker='s', markeredgewidth=2, markeredgecolor='darkred')

    plt.xlabel('Number of Vertices (n)', fontsize=14, fontweight='bold')
    plt.ylabel('Runtime (nanoseconds)', fontsize=14, fontweight='bold')
    plt.title('Articulation Points Detection: Experimental vs Theoretical Runtime\n' +
              f'O(n + m) Complexity - Sparse Graphs (m ≈ 2n)\n' +
              f'Model: T(n) = {C0:,.0f} + {C1:.2f}(n+m) ns',
              fontsize=13, fontweight='bold', pad=20)
    plt.legend(fontsize=12, loc='upper left', framealpha=0.9)
    plt.grid(True, alpha=0.3, linestyle='--', linewidth=1)

    # Add text box
    textstr = f'Time Complexity: O(n + m)\nFor sparse graphs: O(n)\nLinear growth confirmed\nConstant overhead: {C0:,.0f} ns'
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.7)
    plt.text(0.58, 0.20, textstr, transform=plt.gca().transAxes, fontsize=11,
             verticalalignment='top', bbox=props)

    plt.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
    ax = plt.gca()
    ax.tick_params(labelsize=11)

    plt.tight_layout()
    plt.savefig('articulation_points_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("\nGraph saved as 'articulation_points_analysis.png'")

def main():
    """Main execution function"""
    print("\n" + "=" * 80)
    print("BICONNECTIVITY AND ARTICULATION POINTS ANALYSIS")
    print("Linear Time Algorithm - O(n + m)")
    print("=" * 80 + "\n")

    results = run_experiments()

    C0, C1 = calculate_scaling_constants(results)

    create_output_table(results, C0, C1)

    plot_results(results, C0, C1)

    print("\n" + "=" * 80)
    print("ANALYSIS COMPLETE")
    print("=" * 80 + "\n")

if __name__ == "__main__":
    random.seed(42)
    np.random.seed(42)
    main()